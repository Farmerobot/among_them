{"model_techniques": {"claude-3-5-sonnet": {"appeal to credibility": 62, "shifting the burden of proof": 126, "distraction": 187, "appeal to logic": 160, "lying": 61, "projection": 147, "gaslighting": 76, "vagueness": 30, "deception": 83, "appeal to emotion": 17, "strategic voting suggestion": 10, "confirmation bias exploitation": 8, "minimization": 18, "appeal to urgency": 3, "appeal to relationship": 6, "sarcasm": 3, "feigning ignorance": 17, "bandwagon effect": 2, "appeal to rules": 6, "withholding information": 4, "exaggeration": 2, "information overload": 3, "denial without evidence": 2}, "gemini-flash-1-5": {"appeal to credibility": 30, "shifting the burden of proof": 210, "distraction": 156, "appeal to logic": 193, "feigning ignorance": 6, "vagueness": 34, "deception": 26, "projection": 36, "minimization": 30, "lying": 22, "appeal to emotion": 5, "gaslighting": 13, "strategic voting suggestion": 31, "bandwagon effect": 10, "appeal to urgency": 8, "appeal to relationship": 4, "information overload": 1, "appeal to rules": 1, "confirmation bias exploitation": 3}, "llama-3-1-8b-instruct": {"appeal to logic": 236, "shifting the burden of proof": 176, "distraction": 181, "projection": 54, "deception": 9, "lying": 10, "minimization": 25, "feigning ignorance": 4, "vagueness": 22, "appeal to credibility": 5, "strategic voting suggestion": 52, "appeal to emotion": 25, "appeal to urgency": 25, "bandwagon effect": 11, "gaslighting": 12, "appeal to rules": 13, "appeal to relationship": 8, "self-deprecation": 1, "confirmation bias exploitation": 1}, "llama-3-1-405b-instruct": {"appeal to logic": 203, "shifting the burden of proof": 221, "distraction": 126, "feigning ignorance": 13, "strategic voting suggestion": 20, "appeal to urgency": 22, "lying": 9, "deception": 5, "projection": 103, "gaslighting": 24, "minimization": 11, "vagueness": 17, "appeal to relationship": 2, "appeal to emotion": 23, "bandwagon effect": 4, "appeal to credibility": 15, "denial without evidence": 4, "withholding information": 1, "confirmation bias exploitation": 4, "appeal to rules": 4}, "claude-3-5-haiku": {"appeal to logic": 178, "distraction": 76, "appeal to rules": 4, "appeal to credibility": 16, "shifting the burden of proof": 111, "appeal to urgency": 9, "appeal to emotion": 34, "projection": 86, "deception": 15, "vagueness": 20, "lying": 16, "gaslighting": 34, "minimization": 15, "denial without evidence": 6, "strategic voting suggestion": 12, "exaggeration": 3, "feigning ignorance": 1, "bandwagon effect": 8, "appeal to relationship": 1, "confirmation bias exploitation": 1}, "gpt-4o-mini": {"distraction": 159, "shifting the burden of proof": 263, "appeal to logic": 214, "projection": 125, "appeal to emotion": 8, "vagueness": 9, "bandwagon effect": 9, "appeal to credibility": 21, "strategic voting suggestion": 21, "withholding information": 1, "deception": 17, "lying": 15, "appeal to urgency": 3, "gaslighting": 28, "feigning ignorance": 1, "minimization": 4}, "gemini-pro-1-5": {"deception": 96, "lying": 75, "appeal to emotion": 19, "minimization": 30, "shifting the burden of proof": 132, "distraction": 115, "projection": 72, "gaslighting": 58, "appeal to logic": 113, "vagueness": 27, "appeal to urgency": 8, "appeal to rules": 1, "appeal to relationship": 6, "strategic voting suggestion": 17, "appeal to credibility": 23, "bandwagon effect": 6, "feigning ignorance": 15, "confirmation bias exploitation": 4, "information overload": 1, "sarcasm": 1, "self-deprecation": 2}, "gpt-4o": {"appeal to logic": 98, "vagueness": 32, "distraction": 52, "shifting the burden of proof": 98, "strategic voting suggestion": 7, "appeal to credibility": 13, "minimization": 11, "projection": 18, "appeal to emotion": 3, "lying": 7, "deception": 5, "appeal to urgency": 3, "feigning ignorance": 7, "gaslighting": 2, "bandwagon effect": 6, "appeal to rules": 1}}, "model_player_counts": {"claude-3-5-sonnet": 1033, "gemini-flash-1-5": 819, "llama-3-1-8b-instruct": 870, "llama-3-1-405b-instruct": 831, "claude-3-5-haiku": 646, "gpt-4o-mini": 898, "gemini-pro-1-5": 821, "gpt-4o": 363}, "model_input_tokens": {}, "model_output_tokens": {}}