{"model_techniques": {"gemini-flash-1-5": {"providing an alibi": 23, "information gathering": 41, "demand for evidence": 37, "questioning": 29, "contradiction": 11, "appeal to doubt": 39, "accusation": 42, "appeal to logic": 19, "appeal to importance": 22, "call to action": 41, "appeal to agreement": 15, "suggestion": 34, "deflection": 40, "ad hominem": 7, "shifting blame": 9, "appeal to evidence": 22, "confirmation": 4, "appeal to fear": 3}, "llama-3-1-8b-instruct": {"appeal to doubt": 48, "accusation": 43, "deflection": 27, "ad hominem": 2, "demand for evidence": 32, "information gathering": 43, "providing an alibi": 13, "suggestion": 84, "call to action": 52, "appeal to importance": 74, "questioning": 10, "appeal to evidence": 15, "appeal to agreement": 26, "appeal to logic": 36, "shifting blame": 8, "appeal to emotion": 7, "contradiction": 1, "appeal to group": 1, "repetition": 1, "appeal to fear": 2, "confirmation": 1, "appeal to consistency": 1}, "llama-3-1-405b-instruct": {"call to action": 23, "information gathering": 54, "demand for evidence": 44, "questioning": 43, "appeal to logic": 14, "accusation": 63, "appeal to importance": 29, "appeal to doubt": 66, "appeal to agreement": 11, "suggestion": 14, "repetition": 11, "deflection": 35, "providing an alibi": 11, "shifting blame": 16, "contradiction": 10, "ad hominem": 8, "appeal to evidence": 11, "appeal to emotion": 3, "appeal to authority": 2, "tu quoque": 1, "summary": 1, "appeal to consistency": 1}, "gpt-4o-mini": {"information gathering": 55, "appeal to agreement": 8, "call to action": 42, "appeal to doubt": 87, "accusation": 58, "deflection": 51, "shifting blame": 25, "ad hominem": 9, "questioning": 39, "appeal to importance": 31, "appeal to logic": 10, "suggestion": 29, "confirmation": 2, "appeal to evidence": 3, "demand for evidence": 17, "providing an alibi": 10, "contradiction": 2, "appeal to fear": 2, "leading question": 2, "appeal to emotion": 1, "appeal to consistency": 1}, "gemini-pro-1-5": {"providing an alibi": 33, "leading question": 12, "appeal to doubt": 39, "information gathering": 28, "questioning": 45, "accusation": 64, "deflection": 27, "demand for evidence": 22, "appeal to importance": 15, "appeal to logic": 8, "suggestion": 12, "ad hominem": 8, "appeal to emotion": 4, "appeal to evidence": 8, "call to action": 14, "shifting blame": 23, "appeal to agreement": 10, "appeal to authority": 1, "tu quoque": 2, "contradiction": 13, "appeal to fear": 1, "confirmation": 1, "appeal to consistency": 1, "repetition": 1}, "claude-3-5-haiku": {"providing an alibi": 18, "deflection": 38, "accusation": 42, "appeal to importance": 8, "appeal to doubt": 45, "ad hominem": 9, "demand for evidence": 19, "shifting blame": 9, "call to action": 14, "information gathering": 11, "questioning": 8, "appeal to evidence": 6, "appeal to logic": 11, "appeal to emotion": 7, "appeal to fear": 5, "appeal to agreement": 6, "confirmation": 3, "suggestion": 8, "appeal to group": 1, "contradiction": 3}, "gpt-4o": {"information gathering": 52, "appeal to doubt": 8, "call to action": 17, "shifting blame": 5, "appeal to evidence": 3, "appeal to importance": 18, "suggestion": 20, "accusation": 14, "providing an alibi": 22, "deflection": 10, "questioning": 30, "demand for evidence": 6, "confirmation": 1, "contradiction": 1, "appeal to fear": 1, "appeal to agreement": 3, "appeal to logic": 7, "leading question": 1, "tu quoque": 1, "observation": 1}, "claude-3-5-sonnet": {"providing an alibi": 40, "appeal to importance": 14, "information gathering": 19, "contradiction": 41, "demand for evidence": 6, "questioning": 15, "accusation": 85, "deflection": 47, "appeal to doubt": 51, "appeal to logic": 14, "shifting blame": 28, "appeal to evidence": 12, "appeal to authority": 3, "appeal to consistency": 3, "ad hominem": 11, "appeal to emotion": 2, "appeal to agreement": 3, "confirmation": 7, "appeal to fear": 2, "call to action": 3, "repetition": 2, "suggestion": 1}}, "model_player_counts": {"gemini-flash-1-5": 438, "llama-3-1-8b-instruct": 527, "llama-3-1-405b-instruct": 471, "gpt-4o-mini": 484, "gemini-pro-1-5": 392, "claude-3-5-haiku": 271, "gpt-4o": 221, "claude-3-5-sonnet": 409}, "model_input_tokens": {}, "model_output_tokens": {}}